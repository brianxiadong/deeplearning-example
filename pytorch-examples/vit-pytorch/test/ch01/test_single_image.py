#!/usr/bin/env python3
"""
æµ‹è¯•å•å¼ å›¾ç‰‡çš„åˆ†ç±»æ•ˆæœ
"""

import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import sys
import os

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥vit_pytorchæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

from vit_pytorch import SimpleViT

# CIFAR-10 ç±»åˆ«åç§°
CIFAR10_CLASSES = [
    'airplane', 'automobile', 'bird', 'cat', 'deer',
    'dog', 'frog', 'horse', 'ship', 'truck'
]

def get_device():
    """æ™ºèƒ½è®¾å¤‡é€‰æ‹©"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"ğŸš€ ä½¿ç”¨ CUDA è®¾å¤‡")
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
        print(f"ğŸ ä½¿ç”¨ Apple Silicon MPS åŠ é€Ÿ")
    else:
        device = torch.device('cpu')
        print(f"ğŸ’» ä½¿ç”¨ CPU è®¾å¤‡")
    return device

def create_model():
    """åˆ›å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ¨¡å‹æ¶æ„"""
    model = SimpleViT(
        image_size=128,      # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        patch_size=16,
        num_classes=10,
        dim=384,             # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        depth=4,             # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        heads=6,             # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        mlp_dim=768,         # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        channels=3,
        dim_head=64
    )
    return model

def load_model(model_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model()
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    if 'best_acc' in checkpoint:
        print(f"ğŸ“Š æ¨¡å‹æœ€ä½³å‡†ç¡®ç‡: {checkpoint['best_acc']:.2f}%")
    
    return model

def preprocess_image(image_path):
    """é¢„å¤„ç†å›¾åƒ"""
    print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒ: {image_path}")
    
    # ä¸è®­ç»ƒæ—¶ç›¸åŒçš„é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((128, 128)),  # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
    try:
        image = Image.open(image_path).convert('RGB')
        print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {image.size}")
        
        image_tensor = transform(image).unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        print(f"ğŸ“¦ é¢„å¤„ç†åå¼ é‡å½¢çŠ¶: {image_tensor.shape}")
        
        return image_tensor, image
    except Exception as e:
        print(f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {e}")
        return None, None

def predict_image(model, image_tensor, device, top_k=5):
    """å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹"""
    image_tensor = image_tensor.to(device)
    
    with torch.no_grad():
        # å‰å‘ä¼ æ’­
        outputs = model(image_tensor)
        
        # è®¡ç®—æ¦‚ç‡
        probabilities = F.softmax(outputs, dim=1)
        
        # è·å–top-ké¢„æµ‹
        top_probs, top_indices = torch.topk(probabilities, top_k)
        
        results = []
        for i in range(top_k):
            class_idx = top_indices[0][i].item()
            prob = top_probs[0][i].item()
            class_name = CIFAR10_CLASSES[class_idx]
            results.append((class_name, prob))
    
    return results

def display_results(results, image_path):
    """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
    print(f"\nğŸ¯ é¢„æµ‹ç»“æœ - {os.path.basename(image_path)}")
    print("=" * 50)
    
    # æ˜¾ç¤ºæœ€é«˜é¢„æµ‹
    top_class, top_prob = results[0]
    print(f"ğŸ† æœ€å¯èƒ½çš„ç±»åˆ«: {top_class}")
    print(f"ğŸ² ç½®ä¿¡åº¦: {top_prob:.3f} ({top_prob*100:.1f}%)")
    
    # æ˜¾ç¤ºæ‰€æœ‰top-kç»“æœ
    print(f"\nğŸ“Š Top-{len(results)} é¢„æµ‹:")
    for i, (class_name, prob) in enumerate(results):
        if i == 0:
            marker = "ğŸ‘‘"
        elif i == 1:
            marker = "ğŸ¥ˆ"
        elif i == 2:
            marker = "ğŸ¥‰"
        else:
            marker = f"{i+1}."
        
        bar_length = int(prob * 30)  # è¿›åº¦æ¡é•¿åº¦
        bar = "â–ˆ" * bar_length + "â–‘" * (30 - bar_length)
        
        print(f"  {marker} {class_name:12} {prob:.3f} |{bar}| {prob*100:.1f}%")

def analyze_prediction(results):
    """åˆ†æé¢„æµ‹ç»“æœ"""
    print(f"\nğŸ” é¢„æµ‹åˆ†æ:")
    
    top_class, top_prob = results[0]
    
    # ç½®ä¿¡åº¦åˆ†æ
    if top_prob > 0.8:
        confidence_level = "éå¸¸é«˜"
        emoji = "ğŸ¯"
    elif top_prob > 0.6:
        confidence_level = "é«˜"
        emoji = "âœ…"
    elif top_prob > 0.4:
        confidence_level = "ä¸­ç­‰"
        emoji = "âš ï¸"
    else:
        confidence_level = "ä½"
        emoji = "â“"
    
    print(f"  {emoji} ç½®ä¿¡åº¦æ°´å¹³: {confidence_level}")
    
    # ç«äº‰åˆ†æ
    if len(results) > 1:
        second_prob = results[1][1]
        gap = top_prob - second_prob
        
        if gap > 0.3:
            print(f"  ğŸª é¢„æµ‹å¾ˆæ˜ç¡®ï¼Œä¸ç¬¬äºŒåå·®è·: {gap:.3f}")
        elif gap > 0.1:
            print(f"  ğŸ¤” é¢„æµ‹è¾ƒæ˜ç¡®ï¼Œä¸ç¬¬äºŒåå·®è·: {gap:.3f}")
        else:
            print(f"  ğŸ˜• é¢„æµ‹ä¸å¤Ÿæ˜ç¡®ï¼Œä¸ç¬¬äºŒåå·®è·ä»…: {gap:.3f}")

def main():
    """ä¸»å‡½æ•°"""
    print("SimpleViT å•å¼ å›¾ç‰‡åˆ†ç±»æµ‹è¯•")
    print("=" * 50)
    
    # è®¾å¤‡é€‰æ‹©
    device = get_device()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = 'best_simple_vit_optimized.pth'
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹æ–‡ä»¶")
        return
    
    # å›¾ç‰‡è·¯å¾„
    image_path = '../../images/188451751860259_.pic.jpg'
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    try:
        # åŠ è½½æ¨¡å‹
        model = load_model(model_path, device)
        
        # é¢„å¤„ç†å›¾åƒ
        image_tensor, original_image = preprocess_image(image_path)
        if image_tensor is None:
            return
        
        # è¿›è¡Œé¢„æµ‹
        print(f"\nğŸ”® å¼€å§‹é¢„æµ‹...")
        results = predict_image(model, image_tensor, device, top_k=5)
        
        # æ˜¾ç¤ºç»“æœ
        display_results(results, image_path)
        
        # åˆ†æé¢„æµ‹
        analyze_prediction(results)
        
        print(f"\nğŸ’¡ æ³¨æ„: æ­¤æ¨¡å‹æ˜¯åœ¨CIFAR-10æ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œåªèƒ½è¯†åˆ«ä»¥ä¸‹10ä¸ªç±»åˆ«:")
        print(f"   {', '.join(CIFAR10_CLASSES)}")
        print(f"   å¦‚æœæ‚¨çš„å›¾ç‰‡ä¸å±äºè¿™äº›ç±»åˆ«ï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä¸å‡†ç¡®ã€‚")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

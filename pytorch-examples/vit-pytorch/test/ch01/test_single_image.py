#!/usr/bin/env python3
"""
æµ‹è¯•å•å¼ å›¾ç‰‡çš„åˆ†ç±»æ•ˆæœ
"""

import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import sys
import os

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥vit_pytorchæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

from vit_pytorch import SimpleViT

# CIFAR-10 ç±»åˆ«åç§°
CIFAR10_CLASSES = [
    'airplane', 'automobile', 'bird', 'cat', 'deer',
    'dog', 'frog', 'horse', 'ship', 'truck'
]

def get_device():
    """æ™ºèƒ½è®¾å¤‡é€‰æ‹©"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"ğŸš€ ä½¿ç”¨ CUDA è®¾å¤‡")
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
        print(f"ğŸ ä½¿ç”¨ Apple Silicon MPS åŠ é€Ÿ")
    else:
        device = torch.device('cpu')
        print(f"ğŸ’» ä½¿ç”¨ CPU è®¾å¤‡")
    return device

def create_model():
    """åˆ›å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ¨¡å‹æ¶æ„"""
    model = SimpleViT(
        image_size=128,      # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        patch_size=16,
        num_classes=10,
        dim=384,             # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        depth=4,             # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        heads=6,             # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        mlp_dim=768,         # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        channels=3,
        dim_head=64
    )
    return model

def load_model(model_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model()
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    if 'best_acc' in checkpoint:
        print(f"ğŸ“Š æ¨¡å‹æœ€ä½³å‡†ç¡®ç‡: {checkpoint['best_acc']:.2f}%")
    
    return model

def preprocess_image(image_path):
    """é¢„å¤„ç†å›¾åƒ"""
    print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒ: {image_path}")
    
    # ä¸è®­ç»ƒæ—¶ç›¸åŒçš„é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((128, 128)),  # ä¸è®­ç»ƒæ—¶ç›¸åŒ
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
    try:
        image = Image.open(image_path).convert('RGB')
        print(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {image.size}")
        
        image_tensor = transform(image).unsqueeze(0)  # æ·»åŠ batchç»´åº¦
        print(f"ğŸ“¦ é¢„å¤„ç†åå¼ é‡å½¢çŠ¶: {image_tensor.shape}")
        
        return image_tensor, image
    except Exception as e:
        print(f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {e}")
        return None, None

def predict_image(model, image_tensor, device, top_k=5):
    """å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹"""
    image_tensor = image_tensor.to(device)
    
    with torch.no_grad():
        # å‰å‘ä¼ æ’­
        outputs = model(image_tensor)
        
        # è®¡ç®—æ¦‚ç‡
        probabilities = F.softmax(outputs, dim=1)
        
        # è·å–top-ké¢„æµ‹
        top_probs, top_indices = torch.topk(probabilities, top_k)
        
        results = []
        for i in range(top_k):
            class_idx = top_indices[0][i].item()
            prob = top_probs[0][i].item()
            class_name = CIFAR10_CLASSES[class_idx]
            results.append((class_name, prob))
    
    return results

def display_results(results, image_path):
    """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
    print(f"\nğŸ¯ é¢„æµ‹ç»“æœ - {os.path.basename(image_path)}")
    print("=" * 50)
    
    # æ˜¾ç¤ºæœ€é«˜é¢„æµ‹
    top_class, top_prob = results[0]
    print(f"ğŸ† æœ€å¯èƒ½çš„ç±»åˆ«: {top_class}")
    print(f"ğŸ² ç½®ä¿¡åº¦: {top_prob:.3f} ({top_prob*100:.1f}%)")
    
    # æ˜¾ç¤ºæ‰€æœ‰top-kç»“æœ
    print(f"\nğŸ“Š Top-{len(results)} é¢„æµ‹:")
    for i, (class_name, prob) in enumerate(results):
        if i == 0:
            marker = "ğŸ‘‘"
        elif i == 1:
            marker = "ğŸ¥ˆ"
        elif i == 2:
            marker = "ğŸ¥‰"
        else:
            marker = f"{i+1}."
        
        bar_length = int(prob * 30)  # è¿›åº¦æ¡é•¿åº¦
        bar = "â–ˆ" * bar_length + "â–‘" * (30 - bar_length)
        
        print(f"  {marker} {class_name:12} {prob:.3f} |{bar}| {prob*100:.1f}%")

def analyze_prediction(results):
    """åˆ†æé¢„æµ‹ç»“æœ"""
    print(f"\nğŸ” é¢„æµ‹åˆ†æ:")
    
    top_class, top_prob = results[0]
    
    # ç½®ä¿¡åº¦åˆ†æ
    if top_prob > 0.8:
        confidence_level = "éå¸¸é«˜"
        emoji = "ğŸ¯"
    elif top_prob > 0.6:
        confidence_level = "é«˜"
        emoji = "âœ…"
    elif top_prob > 0.4:
        confidence_level = "ä¸­ç­‰"
        emoji = "âš ï¸"
    else:
        confidence_level = "ä½"
        emoji = "â“"
    
    print(f"  {emoji} ç½®ä¿¡åº¦æ°´å¹³: {confidence_level}")
    
    # ç«äº‰åˆ†æ
    if len(results) > 1:
        second_prob = results[1][1]
        gap = top_prob - second_prob
        
        if gap > 0.3:
            print(f"  ğŸª é¢„æµ‹å¾ˆæ˜ç¡®ï¼Œä¸ç¬¬äºŒåå·®è·: {gap:.3f}")
        elif gap > 0.1:
            print(f"  ğŸ¤” é¢„æµ‹è¾ƒæ˜ç¡®ï¼Œä¸ç¬¬äºŒåå·®è·: {gap:.3f}")
        else:
            print(f"  ğŸ˜• é¢„æµ‹ä¸å¤Ÿæ˜ç¡®ï¼Œä¸ç¬¬äºŒåå·®è·ä»…: {gap:.3f}")

# å…¨å±€å˜é‡ï¼Œç”¨äºç¼“å­˜æ¨¡å‹
_cached_model = None
_cached_device = None

def predict_single_image(image_path, model_path='best_simple_vit_optimized.pth', top_k=5, verbose=True):
    """
    å°è£…çš„é¢„æµ‹æ–¹æ³• - åªéœ€æä¾›å›¾ç‰‡è·¯å¾„å³å¯è·å¾—é¢„æµ‹ç»“æœ

    Args:
        image_path (str): å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        model_path (str): æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º 'best_simple_vit_optimized.pth'
        top_k (int): è¿”å›å‰kä¸ªé¢„æµ‹ç»“æœï¼Œé»˜è®¤ä¸º5
        verbose (bool): æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼Œé»˜è®¤ä¸ºTrue

    Returns:
        dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        {
            'success': bool,           # æ˜¯å¦é¢„æµ‹æˆåŠŸ
            'top_prediction': str,     # æœ€é«˜é¢„æµ‹ç±»åˆ«
            'confidence': float,       # æœ€é«˜é¢„æµ‹çš„ç½®ä¿¡åº¦
            'all_predictions': list,   # æ‰€æœ‰top_ké¢„æµ‹ç»“æœ [(class_name, probability), ...]
            'image_size': tuple,       # åŸå§‹å›¾åƒå°ºå¯¸
            'error': str              # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        }
    """
    global _cached_model, _cached_device

    result = {
        'success': False,
        'top_prediction': None,
        'confidence': 0.0,
        'all_predictions': [],
        'image_size': None,
        'error': None
    }

    try:
        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶
        if not os.path.exists(image_path):
            result['error'] = f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"
            if verbose:
                print(f"âŒ {result['error']}")
            return result

        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if not os.path.exists(model_path):
            result['error'] = f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"
            if verbose:
                print(f"âŒ {result['error']}")
            return result

        # åˆå§‹åŒ–è®¾å¤‡å’Œæ¨¡å‹ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼‰
        if _cached_model is None or _cached_device is None:
            if verbose:
                print("ğŸ”§ åˆå§‹åŒ–æ¨¡å‹...")
            _cached_device = get_device()
            _cached_model = load_model(model_path, _cached_device)

        # é¢„å¤„ç†å›¾åƒ
        if verbose:
            print(f"ğŸ–¼ï¸  å¤„ç†å›¾åƒ: {os.path.basename(image_path)}")

        image_tensor, original_image = preprocess_image(image_path)
        if image_tensor is None:
            result['error'] = "å›¾åƒé¢„å¤„ç†å¤±è´¥"
            return result

        result['image_size'] = original_image.size

        # è¿›è¡Œé¢„æµ‹
        if verbose:
            print("ğŸ”® å¼€å§‹é¢„æµ‹...")

        predictions = predict_image(_cached_model, image_tensor, _cached_device, top_k)

        # å¡«å……ç»“æœ
        result['success'] = True
        result['top_prediction'] = predictions[0][0]
        result['confidence'] = predictions[0][1]
        result['all_predictions'] = predictions

        # æ˜¾ç¤ºç»“æœï¼ˆå¦‚æœéœ€è¦ï¼‰
        if verbose:
            display_results(predictions, image_path)
            analyze_prediction(predictions)

        return result

    except Exception as e:
        result['error'] = str(e)
        if verbose:
            print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return result

def simple_predict(image_path):
    """
    æœ€ç®€å•çš„é¢„æµ‹æ¥å£ - åªè¿”å›æœ€å¯èƒ½çš„ç±»åˆ«å’Œç½®ä¿¡åº¦

    Args:
        image_path (str): å›¾ç‰‡æ–‡ä»¶è·¯å¾„

    Returns:
        tuple: (predicted_class, confidence) æˆ– (None, 0.0) å¦‚æœå¤±è´¥
    """
    result = predict_single_image(image_path, verbose=False)
    if result['success']:
        return result['top_prediction'], result['confidence']
    else:
        return None, 0.0

def batch_predict(image_paths, verbose=True):
    """
    æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾ç‰‡

    Args:
        image_paths (list): å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        verbose (bool): æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        list: æ¯å¼ å›¾ç‰‡çš„é¢„æµ‹ç»“æœå­—å…¸åˆ—è¡¨
    """
    results = []

    if verbose:
        print(f"ğŸ“¦ å¼€å§‹æ‰¹é‡é¢„æµ‹ {len(image_paths)} å¼ å›¾ç‰‡...")

    for i, image_path in enumerate(image_paths):
        if verbose:
            print(f"\n--- å›¾ç‰‡ {i+1}/{len(image_paths)} ---")

        result = predict_single_image(image_path, verbose=verbose)
        results.append(result)

    if verbose:
        # æ˜¾ç¤ºæ‰¹é‡é¢„æµ‹æ±‡æ€»
        successful = sum(1 for r in results if r['success'])
        print(f"\nğŸ“Š æ‰¹é‡é¢„æµ‹å®Œæˆ:")
        print(f"   æˆåŠŸ: {successful}/{len(image_paths)}")
        print(f"   å¤±è´¥: {len(image_paths) - successful}/{len(image_paths)}")

    return results

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å°è£…çš„æ–¹æ³•"""
    print("SimpleViT å•å¼ å›¾ç‰‡åˆ†ç±»æµ‹è¯•")
    print("=" * 50)

    # ç¤ºä¾‹1: ä½¿ç”¨è¯¦ç»†é¢„æµ‹æ–¹æ³•
    image_path = '../../images/188451751860259_.pic.jpg'
    print("ğŸ”¥ ç¤ºä¾‹1: è¯¦ç»†é¢„æµ‹")
    result = predict_single_image(image_path)

    if result['success']:
        print(f"\nâœ… é¢„æµ‹æˆåŠŸ!")
        print(f"   æœ€å¯èƒ½ç±»åˆ«: {result['top_prediction']}")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.3f}")
    else:
        print(f"\nâŒ é¢„æµ‹å¤±è´¥: {result['error']}")

    # ç¤ºä¾‹2: ä½¿ç”¨ç®€å•é¢„æµ‹æ–¹æ³•
    print(f"\nğŸ”¥ ç¤ºä¾‹2: ç®€å•é¢„æµ‹")
    predicted_class, confidence = simple_predict(image_path)
    if predicted_class:
        print(f"   ç»“æœ: {predicted_class} (ç½®ä¿¡åº¦: {confidence:.3f})")
    else:
        print(f"   é¢„æµ‹å¤±è´¥")

    print(f"\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print(f"   1. predict_single_image(path) - å®Œæ•´é¢„æµ‹ï¼Œè¿”å›è¯¦ç»†ç»“æœ")
    print(f"   2. simple_predict(path) - ç®€å•é¢„æµ‹ï¼Œåªè¿”å›ç±»åˆ«å’Œç½®ä¿¡åº¦")
    print(f"   3. batch_predict([paths]) - æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾ç‰‡")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
SimpleViT æ¨ç†ç¤ºä¾‹ - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„ SimpleViT æ¨¡å‹è¿›è¡Œé¢„æµ‹
"""

import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
from PIL import Image
import sys
import os
import numpy as np

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥vit_pytorchæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

from vit_pytorch import SimpleViT

# CIFAR-10 ç±»åˆ«åç§°
CIFAR10_CLASSES = [
    'airplane', 'automobile', 'bird', 'cat', 'deer',
    'dog', 'frog', 'horse', 'ship', 'truck'
]

def load_model(model_path, device):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
    """
    print(f"=== åŠ è½½æ¨¡å‹ ===")
    print(f"æ¨¡å‹è·¯å¾„: {model_path}")

    # åˆ›å»ºæ¨¡å‹æ¶æ„ - ä¸è®­ç»ƒæ—¶çš„ä¼˜åŒ–é…ç½®ç›¸åŒ
    model = SimpleViT(
        image_size=128,      # ä¼˜åŒ–åçš„å°ºå¯¸
        patch_size=16,
        num_classes=10,
        dim=384,             # ä¼˜åŒ–åçš„ç»´åº¦
        depth=4,             # ä¼˜åŒ–åçš„å±‚æ•°
        heads=6,             # ä¼˜åŒ–åçš„å¤´æ•°
        mlp_dim=768,         # ä¼˜åŒ–åçš„MLPç»´åº¦
        channels=3,
        dim_head=64
    )
    
    # åŠ è½½æ¨¡å‹æƒé‡
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    
    print(f"æ¨¡å‹åŠ è½½æˆåŠŸ!")
    if 'best_acc' in checkpoint:
        print(f"æ¨¡å‹æœ€ä½³å‡†ç¡®ç‡: {checkpoint['best_acc']:.2f}%")
    
    return model

def preprocess_image(image_path):
    """
    å›¾åƒé¢„å¤„ç†
    """
    transform = transforms.Compose([
        transforms.Resize((128, 128)),  # ä¼˜åŒ–åçš„å°ºå¯¸
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½å›¾åƒ
    image = Image.open(image_path).convert('RGB')
    
    # é¢„å¤„ç†
    input_tensor = transform(image).unsqueeze(0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    
    return input_tensor, image

def predict_single_image(model, image_path, device):
    """
    å¯¹å•å¼ å›¾åƒè¿›è¡Œé¢„æµ‹
    """
    print(f"\n=== é¢„æµ‹å›¾åƒ: {image_path} ===")
    
    # é¢„å¤„ç†å›¾åƒ
    input_tensor, original_image = preprocess_image(image_path)
    input_tensor = input_tensor.to(device)
    
    # é¢„æµ‹
    with torch.no_grad():
        outputs = model(input_tensor)
        probabilities = F.softmax(outputs, dim=1)
        confidence, predicted = torch.max(probabilities, 1)
    
    # è·å–é¢„æµ‹ç»“æœ
    predicted_class = CIFAR10_CLASSES[predicted.item()]
    confidence_score = confidence.item()
    
    print(f"é¢„æµ‹ç±»åˆ«: {predicted_class}")
    print(f"ç½®ä¿¡åº¦: {confidence_score:.4f}")
    
    # æ˜¾ç¤ºå‰5ä¸ªé¢„æµ‹ç»“æœ
    top5_prob, top5_indices = torch.topk(probabilities, 5)
    print(f"\nå‰5ä¸ªé¢„æµ‹ç»“æœ:")
    for i in range(5):
        class_name = CIFAR10_CLASSES[top5_indices[0][i]]
        prob = top5_prob[0][i].item()
        print(f"  {i+1}. {class_name}: {prob:.4f}")
    
    return predicted_class, confidence_score

def predict_batch_images(model, image_folder, device, max_images=10):
    """
    æ‰¹é‡é¢„æµ‹å›¾åƒ
    """
    print(f"\n=== æ‰¹é‡é¢„æµ‹å›¾åƒ ===")
    print(f"å›¾åƒæ–‡ä»¶å¤¹: {image_folder}")
    
    # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
    image_files = []
    
    for file in os.listdir(image_folder):
        if any(file.lower().endswith(ext) for ext in image_extensions):
            image_files.append(os.path.join(image_folder, file))
    
    image_files = image_files[:max_images]  # é™åˆ¶å›¾åƒæ•°é‡
    
    if not image_files:
        print("æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶!")
        return
    
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    
    # æ‰¹é‡é¢„æµ‹
    results = []
    for image_path in image_files:
        try:
            predicted_class, confidence = predict_single_image(
                model, image_path, device
            )
            results.append({
                'image': os.path.basename(image_path),
                'prediction': predicted_class,
                'confidence': confidence
            })
        except Exception as e:
            print(f"å¤„ç†å›¾åƒ {image_path} æ—¶å‡ºé”™: {e}")
    
    # æ˜¾ç¤ºç»“æœæ±‡æ€»
    print(f"\n=== æ‰¹é‡é¢„æµ‹ç»“æœæ±‡æ€» ===")
    for result in results:
        print(f"{result['image']}: {result['prediction']} ({result['confidence']:.4f})")
    
    return results

def demo_with_sample_data(model, device):
    """
    ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œæ¼”ç¤º
    """
    print(f"\n=== ç¤ºä¾‹æ•°æ®æ¼”ç¤º ===")
    
    # åˆ›å»ºéšæœºå›¾åƒæ•°æ®
    random_image = torch.randn(1, 3, 224, 224).to(device)
    
    with torch.no_grad():
        outputs = model(random_image)
        probabilities = F.softmax(outputs, dim=1)
        confidence, predicted = torch.max(probabilities, 1)
    
    predicted_class = CIFAR10_CLASSES[predicted.item()]
    confidence_score = confidence.item()
    
    print(f"éšæœºå›¾åƒé¢„æµ‹:")
    print(f"  é¢„æµ‹ç±»åˆ«: {predicted_class}")
    print(f"  ç½®ä¿¡åº¦: {confidence_score:.4f}")
    
    # æ˜¾ç¤ºæ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
    print(f"\næ‰€æœ‰ç±»åˆ«æ¦‚ç‡:")
    for i, class_name in enumerate(CIFAR10_CLASSES):
        prob = probabilities[0][i].item()
        print(f"  {class_name}: {prob:.4f}")

def get_device():
    """
    æ™ºèƒ½è®¾å¤‡é€‰æ‹©ï¼šä¼˜å…ˆçº§ CUDA > MPS > CPU
    """
    if torch.cuda.is_available():
        device = torch.device('cuda')
        device_name = torch.cuda.get_device_name(0)
        print(f"ğŸš€ ä½¿ç”¨ CUDA è®¾å¤‡: {device_name}")
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
        print(f"ğŸ ä½¿ç”¨ Apple Silicon MPS åŠ é€Ÿ")
    else:
        device = torch.device('cpu')
        print(f"ğŸ’» ä½¿ç”¨ CPU è®¾å¤‡")

    return device

def main():
    """
    ä¸»å‡½æ•°
    """
    print("SimpleViT æ¨ç†ç¤ºä¾‹")
    print("=" * 50)

    # æ™ºèƒ½è®¾å¤‡é€‰æ‹©
    device = get_device()
    
    # æ¨¡å‹è·¯å¾„ - ä¼˜å…ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬
    model_paths = ['best_simple_vit_optimized.pth', 'best_simple_vit.pth']
    model_path = None

    # æŸ¥æ‰¾å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if model_path is None:
        print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨!")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤è®­ç»ƒæ¨¡å‹:")
        print("   python train_simple_vit.py")
        print("\nğŸ² ç°åœ¨ä½¿ç”¨æœªè®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¼”ç¤º...")

        # åˆ›å»ºä¸€ä¸ªæœªè®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¼”ç¤º
        model = SimpleViT(
            image_size=128,      # ä½¿ç”¨ä¼˜åŒ–é…ç½®
            patch_size=16,
            num_classes=10,
            dim=384,
            depth=4,
            heads=6,
            mlp_dim=768,
            channels=3,
            dim_head=64
        ).to(device)
        model.eval()

        demo_with_sample_data(model, device)
        return

    print(f"ğŸ“‚ æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
    
    # åŠ è½½æ¨¡å‹
    model = load_model(model_path, device)
    
    # æ¼”ç¤ºé€‰é¡¹
    print(f"\n=== é€‰æ‹©æ¼”ç¤ºæ¨¡å¼ ===")
    print("1. å•å¼ å›¾åƒé¢„æµ‹")
    print("2. æ‰¹é‡å›¾åƒé¢„æµ‹")
    print("3. éšæœºæ•°æ®æ¼”ç¤º")
    
    try:
        choice = input("è¯·é€‰æ‹©æ¨¡å¼ (1/2/3): ").strip()
        
        if choice == '1':
            image_path = input("è¯·è¾“å…¥å›¾åƒè·¯å¾„: ").strip()
            if os.path.exists(image_path):
                predict_single_image(model, image_path, device)
            else:
                print(f"å›¾åƒæ–‡ä»¶ {image_path} ä¸å­˜åœ¨!")
        
        elif choice == '2':
            folder_path = input("è¯·è¾“å…¥å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„: ").strip()
            if os.path.exists(folder_path):
                predict_batch_images(model, folder_path, device)
            else:
                print(f"æ–‡ä»¶å¤¹ {folder_path} ä¸å­˜åœ¨!")
        
        elif choice == '3':
            demo_with_sample_data(model, device)
        
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨éšæœºæ•°æ®æ¼”ç¤º")
            demo_with_sample_data(model, device)
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
